{
	"statistics": {
		"identical": 2138,
		"minorChanges": 68,
		"relatedMeaning": 6
	},
	"text": {
		"value": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSearching for duplicates...\n\n\n\n\n\n\nCreate Page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMenu\n\n\n\n\n\n\n0 IQ\n\n0 BRAIN\n\n\n\n\nOREID Logins\n\n\n\n\n\n\nFacebook\n\n\n\n\n\n\nTwitter\n\n\n\nGet Scatter\n\nCreate Page\n\nRecent Activity\n\nForum\n\nHelp\n\nGet IQ\n\n\n\n\n\n\n\n\n IQ\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlagiarism detection\n\n\n\n\n\n\n Software-assisted detection \n\n\n\n\n\n\n In text documents \n\n\n\n\n\n\n Approaches \n\n\n\n\n\n\n Fingerprinting \n\n\n\n\n\n\n String matching \n\n\n\n\n\n\n Bag of words \n\n\n\n\n\n\n Citation analysis \n\n\n\n\n\n\n Stylometry \n\n\n\n\n\n\n Performance \n\n\n\n\n\n\n Software \n\n\n\n\n\n\n In source code \n\n\n\n\n\n\nImages &amp; Videos\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nSee Also\n\n\n\n\n\n\n\n\n×\nEveripedia is getting a makeover! How can we improve? Donate a few minutes to share your feedback: Here\n\n\n\n\n\n\nPlagiarism detection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCopy URL\n\n\n\n\nEmbed / Widget\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuggested Hashtags\n\n\nPlagiarism detection wiki\n\nPlagiarism detection review\n\nPlagiarism detection history\n\nPlagiarism detection encyclopedia\n\nPlagiarism detection facts\n\n\n\n\n\n\nQR Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification of computer-assisted plagiarism detection methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n     Plagiarism detection  is the process of locating instances of  plagiarism within a work or document. The widespread use of computers and the advent of the Internet has made it easier to plagiarize the work of others. Most cases of plagiarism are found in academia, where documents are typically essays or reports. However, plagiarism can be found in virtually any field, including scientific papers, art designs, and source code. \n  Detection of plagiarism can be either manual or software-assisted. Manual detection requires substantial effort and excellent memory, and is impractical in cases where too many documents must be compared, or original documents are not available for comparison. Software-assisted detection allows vast collections of documents to be compared to each other, making successful detection much more likely. \n  The practice of plagiarizing by use of sufficient word substitutions to elude detection software is known as  rogeting.   [2]  \n  \n  \n   Software-assisted detection    Computer-assisted plagiarism detection (CaPD) is an  Information retrieval (IR) task supported by specialized IR systems, referred to as plagiarism detection systems (PDS). \n   In text documents    Systems for text-plagiarism detection implement one of two generic detection approaches, one being external, the other being intrinsic.   [4]  External detection systems compare a suspicious document with a reference collection, which is a set of documents assumed to be genuine.   [6]  Based on a chosen  document model and predefined similarity criteria, the detection task is to retrieve all documents that contain text that is similar to a degree above a chosen threshold to text in the suspicious document.   [8]  Intrinsic PDS solely analyze the text to be evaluated without performing comparisons to external documents. This approach aims to recognize changes in the unique writing style of an author as an indicator for potential plagiarism.   [10]  PDS are not capable of reliably identifying plagiarism without human judgment. Similarities are computed with the help of predefined document models and might represent false positives.   [11]    [12]    [14]    [15]    [16]  \n   Approaches    The figure below represents a classification of all detection approaches currently in use for computer-assisted plagiarism detection. The approaches are characterized by the type of similarity assessment they undertake: global or local. Global similarity assessment approaches use the characteristics taken from larger parts of the text or the document as a whole to compute similarity, while local methods only examine pre-selected text segments as input. \n  \n   Fingerprinting    Fingerprinting is currently the most widely applied approach to plagiarism detection. This method forms representative digests of documents by selecting a set of multiple substrings (  n-grams) from them. The sets represent the fingerprints and their elements are called minutiae.   [19]    [20]  A suspicious document is checked for plagiarism by computing its fingerprint and querying minutiae with a precomputed index of fingerprints for all documents of a reference collection. Minutiae matching with those of other documents indicate shared text segments and suggest potential plagiarism if they exceed a chosen similarity threshold.   [22]  Computational resources and time are limiting factors to fingerprinting, which is why this method typically only compares a subset of minutiae to speed up the computation and allow for checks in very large collection, such as the Internet.   [19]  \n   String matching     String matching is a prevalent approach used in computer science. When applied to the problem of plagiarism detection, documents are compared for verbatim text overlaps. Numerous methods have been proposed to tackle this task, of which some have been adapted to external plagiarism detection. Checking a suspicious document in this setting requires the computation and storage of efficiently comparable representations for all documents in the reference collection to compare them pairwise. Generally, suffix document models, such as  suffix trees or suffix vectors, have been used for this task. Nonetheless, substring matching remains computationally expensive, which makes it a non-viable solution for checking large collections of documents.   [24]    [25]    [27]  \n   Bag of words    Bag of words analysis represent the adoption of  vector space retrieval, a traditional IR concept, to the domain of plagiarism detection. Documents are represented as one or multiple vectors, e.g. for different document parts, which are used for pair wise similarity computations. Similarity computation may then rely on the traditional  cosine similarity measure, or on more sophisticated similarity measures.   [29]    [30]    [31]  \n   Citation analysis    Citation-based plagiarism detection (CbPD)   [32]  relies on citation analysis, and is the only approach to plagiarism detection that does not rely on the textual similarity.   [34]  CbPD examines the citation and reference information in texts to identify similar  patterns in the citation sequences. As such, this approach is suitable for scientific texts, or other academic documents that contain citations. Citation analysis to detect plagiarism is a relatively young concept. It has not been adopted by commercial software, but a first prototype of a citation-based plagiarism detection system exists.   [36]  Similar order and proximity of citations in the examined documents are the main criteria used to compute citation pattern similarities. Citation patterns represent subsequences non-exclusively containing citations shared by the documents compared.   [34]    [38]  Factors, including the absolute number or relative fraction of shared citations in the pattern, as well as the probability that citations co-occur in a document are also considered to quantify the patterns’ degree of similarity.   [34]    [38]    [40]    [42]  \n   Stylometry     Stylometry subsumes statistical methods for quantifying an author’s unique writing style   [43]    [46]  and is mainly used for authorship attribution or intrinsic CaPD. By constructing and comparing stylometric models for different text segments, passages that are stylistically different from others, hence potentially plagiarized, can be detected.   [10]  \n   Performance    Comparative evaluations of plagiarism detection systems   [6]    [47]    [48]    [49]    [50]    [51]  indicate that their performance depends on the type of plagiarism present (see figure). Except for citation pattern analysis, all detection approaches rely on textual similarity. It is therefore symptomatic that detection accuracy decreases the more plagiarism cases are obfuscated. \n  \n  Literal copies, aka copy and paste (c&amp;p) plagiarism, or modestly disguised plagiarism cases can be detected with high accuracy by current external PDS if the source is accessible to the software. Especially substring matching procedures achieve a good performance for c&amp;p plagiarism, since they commonly use lossless document models, such as  suffix trees. The performance of systems using fingerprinting or bag of words analysis in detecting copies depends on the information loss incurred by the document model used. By applying flexible chunking and selection strategies, they are better capable of detecting moderate forms of disguised plagiarism when compared to substring matching procedures. \n  Intrinsic plagiarism detection using  stylometry can overcome the boundaries of textual similarity to some extent by comparing linguistic similarity. Given that the stylistic differences between plagiarized and original segments are significant and can be identified reliably, stylometry can help in identifying disguised and  paraphrased plagiarism. Stylometric comparisons are likely to fail in cases where segments are strongly paraphrased to the point where they more closely resemble the personal writing style of the plagiarist or if a text was compiled by multiple authors. The results of the International Competitions on Plagiarism Detection held in 2009, 2010 and 2011,   [6]    [50]    [51]  as well as experiments performed by Stein,   [54]  indicate that stylometric analysis seems to work reliably only for document lengths of several thousand or tens of thousands of words, which limits the applicability of the method to CaPD settings. \n  An increasing amount of research is performed on methods and systems capable of detecting translated plagiarisms. Currently, cross-language plagiarism detection (CLPD) is not viewed as a mature technology   [56]  and respective systems have not been able to achieve satisfying detection results in practice.   [49]  \n  Citation-based plagiarism detection using citation pattern analysis is capable of identifying stronger paraphrases and translations with higher success rates when compared to other detection approaches, because it is independent of textual characteristics.   [34]    [40]  However, since citation-pattern analysis depends on the availability of sufficient citation information, it is limited to academic texts. It remains inferior to text-based approaches in detecting shorter plagiarized passages, which are typical for cases of copy-and-paste or shake-and-paste plagiarism; the latter refers to mixing slightly altered fragments from different sources.   [57]  \n   Software    The design of plagiarism detection software for use with text documents is characterized by a number of factors: \n     Factor   Description and alternatives      Scope of search    In the public internet, using search engines / Institutional databases / Local, system-specific database.      Analysis time    Delay between the time a document is submitted and the time when results are made available.      Document capacity / Batch processing    Number of documents the system can process per unit of time.      Check intensity    How often and for which types of document fragments (paragraphs, sentences, fixed-length word sequences) does the system query external resources, such as search engines.      Comparison algorithm type    The algorithms that define the way the system uses to compare documents against each other.      Precision and Recall    Number of documents correctly flagged as plagiarized compared to the total number of flagged documents, and to the total number of documents that were actually plagiarized. High precision means that few  false positives were found, and high recall means that few  false negatives were left undetected.      Most large-scale plagiarism detection systems use large, internal databases (in addition to other resources) that grow with each additional document submitted for analysis. However, this feature is considered by some as a  violation of student copyright. \n  The following systems are mostly web-based, and are closed-source, with the exception of CitePlag and CopyTracker. The following list is non-exhaustive (see also  Comparison of anti-plagiarism software): \n          Free of charge     Chimpsky   [58]    [59]    CitePlag   [38]    CopyTracker   [58]    [59]    [60]     eTBLAST   Plagium   [59]    [61]    SeeSources   [59]    [62]          Commercial      Attributor    Copyscape    PlagTracker   Iparadigms:  Ithenticate,  Turnitin   PlagiarismDetect   [58]    [59]    PlagScan   [58]    [59]    VeriGuide   The Plagiarism Checker   [63]    [65]        \n   In source code    Plagiarism in computer source code is also frequent, and requires different tools than those used for text comparisons in document. Significant research has been dedicated to academic source-code plagiarism.   [66]  \n  A distinctive aspect of source-code plagiarism is that there are no  essay mills, such as can be found in traditional plagiarism. Since most programming assignments expect students to write programs with very specific requirements, it is very difficult to find existing programs that already meet them. Since integrating external code is often harder than writing it from scratch, most plagiarizing students choose to do so from their peers. \n  According to Roy and Cordy,   [67]  source-code similarity detection algorithms can be classified as based on either \n   Strings – look for exact textual matches of segments, for instance five-word runs. Fast, but can be confused by renaming identifiers. \n  Tokens – as with strings, but using a  lexer to convert the program into  tokens first. This discards whitespace, comments, and identifier names, making the system more robust to simple text replacements. Most academic plagiarism detection systems work at this level, using different algorithms to measure the similarity between token sequences. \n   Parse Trees – build and compare parse trees. This allows higher-level similarities to be detected. For instance, tree comparison can normalize conditional statements, and detect equivalent constructs as similar to each other. \n   Program Dependency Graphs (PDGs) – a PDG captures the actual flow of control in a program, and allows much higher-level equivalences to be located, at a greater expense in complexity and calculation time. \n  Metrics – metrics capture 'scores' of code segments according to certain criteria; for instance, \"the number of loops and conditionals\", or \"the number of different variables used\". Metrics are simple to calculate and can be compared quickly, but can also lead to false positives: two fragments with the same scores on a set of metrics may do entirely different things. \n  Hybrid approaches – for instance, parse trees +  suffix trees can combine the detection capability of parse trees with the speed afforded by suffix trees, a type of string-matching data structure. \n   The previous classification was developed for  code refactoring, and not for academic plagiarism detection (an important goal of refactoring is to avoid duplicate code, referred to as  code clones in the literature). The above approaches are effective against different levels of similarity; low-level similarity refers to identical text, while high-level similarity can be due to similar specifications. In an academic setting, when all students are expected to code to the same specifications, functionally equivalent code (with high-level similarity) is entirely expected, and only low-level similarity is considered as proof of cheating. \n      Category:Plagiarism detectors \n   Comparison of anti-plagiarism software \n   Locality sensitive hashing \n   Nearest neighbor search \n   Kolmogorov complexity#Compression – used to estimate similarity between token sequences in several systems \n  \n \n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage &amp; Video Gallery\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDetection performance of CaPD approaches depending on the type of plagiarism being present\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReference Links For This Wiki\n\n\n\n\n\n\nAll information for Plagiarism detection's wiki comes from the below links. Any source is valid, including Twitter, Facebook, Instagram, and LinkedIn. Pictures, videos, biodata, and files relating to Plagiarism detection are also acceptable encyclopedic sources.\n\n\n\n\n\n\n\n\nhttps://en.wikipedia.org/wiki/Plagiarism_detection\nThe original version of this page is from Wikipedia, you can edit the page right here on Everipedia. Text is available under the Creative Commons Attribution-ShareAlike License. Additional terms may apply. See\n\neveripedia.org/everipedia-terms\n\nfor further details. Images/media credited individually (click the icon for details).\n\n\n\n\n\n07/26/2016 05:23:27 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://archive.plagiarismadvice.org/images/stories/old_site/media/2008papers/P21%20Weber-Wulff.pdf\nIn Proceedings of the 3rd International Plagiarism Conference, Newcastle Upon Tyne\n\n\n\n\n\n07/26/2016 05:23:32 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.alexaic.com/alexaicfiles/presentation2010/day3/028001.pdf\n\"Plagiarism What is it? How to avoid it?\"\n\n\n\n\n\n07/26/2016 05:23:33 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://shodhganga.inflibnet.ac.in/dxml/bitstream/handle/1944/1629/37.pdf?sequence=1\n\"Diagnosing Plague: Tools And Techniques For Detecting Plagiarism\"\n\n\n\n\n\n07/26/2016 05:23:33 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://web.archive.org/web/20120918012057/http://copytracker.org/\n\"CopyTracker.org\"\n\n\n\n\n\n07/26/2016 05:23:33 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://today.msnbc.msn.com/id/32657885/ns/today-today_tech/\n\"Steal this story? Beware Net’s plagiarism ‘cops’\"\n\n\n\n\n\n07/26/2016 05:23:33 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.plagscan.com/seesources/\nSeeSources\n\n\n\n\n\n07/26/2016 05:23:33 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.dustball.com/cs/plagiarism.checker\nPlagiarismChecker\n\n\n\n\n\n07/26/2016 05:23:33 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://web.archive.org/web/20120324194342/http://shodhganga.inflibnet.ac.in/dxml/bitstream/handle/1944/1629/37.pdf?sequence=1\n\"Encouraging Academic Honesty through Anti-plagiarism Software\"\n\n\n\n\n\n07/26/2016 05:23:33 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://ir.inflibnet.ac.in/dxml/bitstream/handle/1944/1068/55.pdf?sequence=1\nthe original\n\n\n\n\n\n07/26/2016 05:23:34 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.ics.heacademy.ac.uk/resources/assessment/plagiarism/research_sourcecode.html\n\"Plagiarism Prevention and Detection - On-line Resources on Source Code Plagiarism\"\n\n\n\n\n\n07/26/2016 05:23:34 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://research.cs.queensu.ca/TechReports/Reports/2007-541.pdf\n\"A Survey on Software Clone Detection Research\"\n\n\n\n\n\n07/26/2016 05:23:34 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttps://everipedia-storage.s3.amazonaws.com/NewlinkFiles/4234688/22800406.png\n\n\n\n\nDetection performance of CaPD approaches depending on the type of plagiarism being present\n\n\n\n\n\n\n\n07/26/2016 05:23:34 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttps://www.timeshighereducation.co.uk/news/sinister-buttocks-roget-would-blush-at-the-crafty-cheek/2015027.article\n\"Sinister buttocks? Roget would blush at the crafty cheek Middlesex lecturer gets to the bottom of meaningless phrases found while marking essays\"\n\n\n\n\n\n07/26/2016 05:23:27 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.uni-weimar.de/medien/webis/publications/papers/stein_2007o.pdf\n\"Plagiarism Analysis, Authorship Identification, and Near-Duplicate Detection PAN’07\"\n\n\n\n\n\n07/26/2016 05:23:27 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1145/1328964.1328976\n10.1145/1328964.1328976\n\n\n\n\n\n07/26/2016 05:23:27 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.uni-weimar.de/medien/webis/research/events/pan-09/pan09-papers-final/potthast09-overview-first-international-competition-plagiarism-detection.pdf\nPAN09 - 3rd Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse and 1st International Competition on Plagiarism Detection\n\n\n\n\n\n07/26/2016 05:23:27 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.worldcat.org/issn/1613-0073\n1613-0073\n\n\n\n\n\n07/26/2016 05:23:27 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.uni-weimar.de/medien/webis/publications/papers/stein_2007f.pdf\nProceedings 30th Annual International ACM SIGIR Conference\n\n\n\n\n\n07/26/2016 05:23:27 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1145/1277741.1277928\n10.1145/1277741.1277928\n\n\n\n\n\n07/26/2016 05:23:28 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.uni-weimar.de/medien/webis/publications/papers/stein_2006d.pdf\nAdvances in Information Retrieval 28th European Conference on IR Research, ECIR 2006, London, UK, April 10–12, 2006 Proceedings\n\n\n\n\n\n07/26/2016 05:23:28 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1007/11735106_66\n10.1007/11735106_66\n\n\n\n\n\n07/26/2016 05:23:28 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.plagiarismadvice.org/images/stories/old_site/media/2006papers/JunPengBao.pdf\n2nd International Plagiarism Conference Proceedings\n\n\n\n\n\n07/26/2016 05:23:28 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.ir.shef.ac.uk/cloughie/papers/plagiarism2000.pdf\nPlagiarism in natural and programming languages an overview of current tools and technologies\n\n\n\n\n\n07/26/2016 05:23:28 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.essaycoursework.com/howtowriteessaynet/pdf/plagiarism-higheredu.pdf\n\"Plagiarism issues for higher education\"\n\n\n\n\n\n07/26/2016 05:23:28 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1108/03055720010804005\n10.1108/03055720010804005\n\n\n\n\n\n07/26/2016 05:23:28 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.bcu.academia.edu/documents/0009/4554/Lancaster_2003.pdf\nEffective and Efficient Plagiarism Detection\n\n\n\n\n\n07/26/2016 05:23:28 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.editlib.org/p/26021\nProceedings of World Conference on Educational Multimedia, Hypermedia and Telecommunications 2007\n\n\n\n\n\n07/26/2016 05:23:28 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://goanna.cs.rmit.edu.au/~jz/fulltext/jasist-tch.pdf\n\"Methods for Identifying Versioned and Plagiarised Documents\"\n\n\n\n\n\n07/26/2016 05:23:28 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1002/asi.10170\n10.1002/asi.10170\n\n\n\n\n\n07/26/2016 05:23:28 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.2680\n10.1.1.18.2680\n\n\n\n\n\n07/26/2016 05:23:29 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.uni-weimar.de/medien/webis/publications/papers/stein_2005a.pdf\nProceedings of the I-KNOW ‘05, 5th International Conference on Knowledge Management, Graz, Austria\n\n\n\n\n\n07/26/2016 05:23:29 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://ilpubs.stanford.edu:8090/112/1/1995-43.pdf\nProceedings of the 1995 ACM SIGMOD International Conference on Management of Data\n\n\n\n\n\n07/26/2016 05:23:29 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1145/223784.223855\n10.1145/223784.223855\n\n\n\n\n\n07/26/2016 05:23:29 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.csse.monash.edu.au/projects/MDR/papers/dl2000-monostori.pdf\nProceedings of the fifth ACM conference on Digital libraries\n\n\n\n\n\n07/26/2016 05:23:29 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1145/336597.336667\n10.1145/336597.336667\n\n\n\n\n\n07/26/2016 05:23:29 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://cm.bell-labs.com/cm/cs/doc/93/2-bsb-1.ps.gz\nOn Finding Duplication in Strings and Software\n\n\n\n\n\n07/26/2016 05:23:29 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1145/860435.860456\n10.1145/860435.860456\n\n\n\n\n\n07/26/2016 05:23:29 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.9.6155\n10.1.1.9.6155\n\n\n\n\n\n07/26/2016 05:23:29 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.cs.cityu.edu.hk/~rynson/papers/sac97.pdf\nSAC ’97: Proceedings of the 1997 ACM symposium on Applied computing\n\n\n\n\n\n07/26/2016 05:23:29 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1145/331697.335176\n10.1145/331697.335176\n\n\n\n\n\n07/26/2016 05:23:30 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://proceedings.informingscience.org/InSITE2007/IISITv4p601-614Dreh383.pdf\n\"Automatic Conceptual Analysis for Plagiarism Detection\"\n\n\n\n\n\n07/26/2016 05:23:30 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.uni-weimar.de/medien/webis/research/events/pan-09/pan09-papers-final/zechner09-external-and-intrinsic-plagiarism-detection-using-vsm.pdf\nPAN09 - 3rd Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse and 1st International Competition on Plagiarism Detection\n\n\n\n\n\n07/26/2016 05:23:30 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.springer.com/springer+vieweg/it+%26+informatik/k%C3%BCnstliche+intelligenz/book/978-3-658-06393-1\nhttp://www.springer.com/springer+vieweg/it+%26+informatik/k%C3%BCnstliche+intelligenz/book/978-3-658-06393-1\n\n\n\n\n\n07/26/2016 05:23:30 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.sciplore.org/publications/2010-Citation_Based_Plagiarism_Detection_-_A_New_Approach_to_Identify_Plagiarized_Work_Language_Independently_-_preprint.pdf\nProceedings of the 21st ACM Conference on Hypertext and Hypermedia (HT'10)\n\n\n\n\n\n07/26/2016 05:23:30 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1145/1810617.1810671\n10.1145/1810617.1810671\n\n\n\n\n\n07/26/2016 05:23:30 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://sciplore.org/wp-content/papercite-data/pdf/gipp13.pdf\nProceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval\n\n\n\n\n\n07/26/2016 05:23:30 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1145/2484028.2484214\n10.1145/2484028.2484214\n\n\n\n\n\n07/26/2016 05:23:30 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.sciplore.org/publications/2011-Citation_Pattern_Matching_Algorithms_for_Citation-based_Plagiarism_Detection--Greedy_Citation_Tiling,_Citation_Chunking_and_Longest_Common_Citation_Sequence.pdf\nProceedings of the 11th ACM Symposium on Document Engineering (DocEng2011)\n\n\n\n\n\n07/26/2016 05:23:30 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1145/2034691.2034741\n10.1145/2034691.2034741\n\n\n\n\n\n07/26/2016 05:23:30 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.sciplore.org/publications/2011-Comparative_Evaluation_of_Text-_and_Citation-based_Plagiarism_Detection_Approaches_using_GuttenPlag.pdf\nProceedings of 11th ACM/IEEE-CS Joint Conference on Digital Libraries (JCDL’11)\n\n\n\n\n\n07/26/2016 05:23:31 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1145/1998076.1998124\n10.1145/1998076.1998124\n\n\n\n\n\n07/26/2016 05:23:31 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.sciplore.org/publications/2009-Citation_Proximity_Analysis_(CPA)_-_A_new_approach_for_identifying_related_work_based_on_Co-Citation_Analysis_--_preprint.pdf\nProceedings of the 12th International Conference on Scientometrics and Informetrics (ISSI’09)\n\n\n\n\n\n07/26/2016 05:23:31 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.worldcat.org/issn/2175-1935\n2175-1935\n\n\n\n\n\n07/26/2016 05:23:31 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1093/llc/13.3.111\n10.1093/llc/13.3.111\n\n\n\n\n\n07/26/2016 05:23:31 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.mathcs.duq.edu/~juola/papers.d/fnt-aa.pdf\n\"Authorship Attribution\"\n\n\n\n\n\n07/26/2016 05:23:31 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1561/1500000005\n10.1561/1500000005\n\n\n\n\n\n07/26/2016 05:23:31 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.worldcat.org/issn/1554-0669\n1554-0669\n\n\n\n\n\n07/26/2016 05:23:31 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://plagiat.htw-berlin.de/ff-alt/05hilfen/programme.html\nPortal Plagiat - Softwaretest 2004\n\n\n\n\n\n07/26/2016 05:23:31 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://plagiat.htw-berlin.de/software/2008/\nPortal Plagiat - Softwaretest 2008\n\n\n\n\n\n07/26/2016 05:23:31 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://plagiat.htw-berlin.de/software/2010-2/\nPortal Plagiat - Softwaretest 2010\n\n\n\n\n\n07/26/2016 05:23:32 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://clef2010.org/resources/proceedings/clef2010labs_submission_125.pdf\nNotebook Papers of CLEF 2010 LABs and Workshops, 22–23 September, Padua, Italy\n\n\n\n\n\n07/26/2016 05:23:32 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.uni-weimar.de/medien/webis/publications/papers/stein_2011t.pdf\nNotebook Papers of CLEF 2011 LABs and Workshops, 19–22 September, Amsterdam, Netherlands\n\n\n\n\n\n07/26/2016 05:23:32 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.uni-weimar.de/medien/webis/publications/papers/stein_2011a.pdf\n\"Intrinsic Plagiarism Analysis\"\n\n\n\n\n\n07/26/2016 05:23:32 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1007/s10579-010-9115-y\n10.1007/s10579-010-9115-y\n\n\n\n\n\n07/26/2016 05:23:32 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.worldcat.org/issn/1574-020X\n1574-020X\n\n\n\n\n\n07/26/2016 05:23:32 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.uni-weimar.de/medien/webis/publications/papers/stein_2011b.pdf\n\"Cross-Language Plagiarism Detection\"\n\n\n\n\n\n07/26/2016 05:23:32 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://dx.doi.org/10.1007/s10579-009-9114-z\n10.1007/s10579-009-9114-z\n\n\n\n\n\n07/26/2016 05:23:32 PM UTC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSee Also\n\n\n\n\n\n\nOther wiki pages related to Plagiarism detection.\n\n\n\n\n\nSuffix tree\n\n\n\n\n\n\n\n\n\n\nComparison of anti-plagiarism software\n\n\n\n\n\n\n\n\n\n\nEOS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow/Hide Left Slide Menu\nShow/Hide Right Slide Menu\nShow/Hide Top Slide Menu\nShow/Hide Bottom Slide Menu\n\n\n\n\n\n\n\n\n\n\n\nQmYn2DbdRNAx162eV1GMoPiX2c3Yd3aaPTHjGCr4zudQZS\n\n\n\n\n\n\n\nAbout\n\nFAQ\n\nContact\n\nTerms\n\nForum\n\nGet IQ\n\nInvestors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2018 Everipedia International \nPowered by EOS.IO\n\n\n\n\nAPI by LibertyBlock\n\n\n\n\nand Scatter\n\n\n\n\n\n\n\n\n\n\u2028\n",
		"pages": {
			"startPosition": [
				0,
				2172,
				3934,
				5658,
				7473,
				9285,
				11096,
				12995,
				14665,
				16612,
				20235,
				23705,
				27854
			]
		},
		"comparison": {
			"identical": {
				"source": {
					"chars": {
						"starts": [
							339,
							726,
							1666,
							1700,
							1898,
							2037,
							2177,
							2404,
							2638,
							3664,
							4215,
							4407,
							4502,
							4848,
							5094,
							5116,
							5875,
							5894,
							6317,
							6341,
							6388,
							6516,
							6943,
							7199,
							7560,
							7829,
							7908,
							8290,
							9686,
							9733,
							10141,
							10241,
							10506,
							10910,
							11044,
							11225,
							11352,
							11470,
							11798,
							12138,
							12411,
							12432,
							12645,
							13119,
							15486,
							15644,
							15909,
							16601,
							16823,
							17253,
							17958,
							18335,
							18630,
							18884,
							19176,
							19423,
							20026,
							20506,
							21033,
							21364,
							21732,
							22050,
							22361,
							23407,
							23667,
							24267,
							24360,
							26668,
							26745
						],
						"lengths": [
							378,
							563,
							17,
							181,
							124,
							127,
							213,
							218,
							174,
							456,
							181,
							76,
							330,
							229,
							6,
							733,
							6,
							398,
							8,
							35,
							111,
							414,
							237,
							216,
							235,
							47,
							282,
							1378,
							35,
							392,
							84,
							239,
							372,
							103,
							151,
							96,
							92,
							301,
							309,
							242,
							9,
							195,
							462,
							2203,
							106,
							139,
							77,
							58,
							127,
							93,
							92,
							61,
							98,
							81,
							60,
							46,
							67,
							142,
							74,
							111,
							74,
							79,
							93,
							78,
							88,
							82,
							83,
							67,
							27
						]
					},
					"words": {
						"starts": [
							49,
							111,
							238,
							240,
							265,
							283,
							304,
							341,
							376,
							530,
							602,
							628,
							641,
							690,
							728,
							730,
							836,
							839,
							898,
							900,
							904,
							924,
							986,
							1018,
							1065,
							1099,
							1105,
							1157,
							1356,
							1363,
							1422,
							1436,
							1468,
							1519,
							1538,
							1560,
							1579,
							1596,
							1641,
							1691,
							1728,
							1731,
							1760,
							1833,
							2179,
							2199,
							2237,
							2326,
							2353,
							2408,
							2504,
							2551,
							2585,
							2617,
							2652,
							2687,
							2770,
							2833,
							2905,
							2945,
							2990,
							3028,
							3067,
							3202,
							3238,
							3309,
							3322,
							3613,
							3622
						],
						"lengths": [
							60,
							79,
							0,
							23,
							16,
							19,
							35,
							33,
							24,
							64,
							24,
							11,
							47,
							36,
							0,
							104,
							1,
							57,
							0,
							2,
							18,
							60,
							30,
							33,
							31,
							4,
							38,
							197,
							5,
							57,
							12,
							30,
							48,
							16,
							19,
							16,
							14,
							42,
							47,
							34,
							1,
							27,
							71,
							329,
							12,
							20,
							6,
							6,
							17,
							12,
							9,
							6,
							12,
							11,
							8,
							6,
							10,
							17,
							10,
							14,
							9,
							9,
							10,
							11,
							11,
							10,
							9,
							7,
							3
						]
					}
				},
				"suspected": {
					"chars": {
						"starts": [
							1148,
							1529,
							2123,
							2154,
							2352,
							2495,
							2639,
							2871,
							3110,
							3354,
							3836,
							4030,
							4133,
							4483,
							4735,
							4755,
							5529,
							5545,
							5984,
							6005,
							6056,
							6188,
							6620,
							6884,
							7269,
							7542,
							7645,
							7934,
							9347,
							9398,
							9812,
							9918,
							10191,
							10597,
							10716,
							10889,
							11004,
							11110,
							11431,
							11762,
							12628,
							12646,
							12865,
							13346,
							15715,
							18886,
							19152,
							19907,
							20196,
							20717,
							21324,
							21524,
							21928,
							22122,
							22427,
							22691,
							23064,
							19551,
							24225,
							24517,
							24988,
							25365,
							25769,
							26889,
							27087,
							16838,
							18261,
							16465,
							16542
						],
						"lengths": [
							380,
							565,
							17,
							184,
							124,
							127,
							214,
							218,
							174,
							456,
							181,
							76,
							330,
							229,
							6,
							734,
							6,
							400,
							8,
							35,
							111,
							415,
							237,
							216,
							235,
							47,
							282,
							1383,
							35,
							394,
							84,
							239,
							372,
							103,
							157,
							98,
							94,
							308,
							313,
							243,
							9,
							195,
							465,
							2225,
							106,
							138,
							77,
							58,
							127,
							93,
							92,
							61,
							98,
							81,
							60,
							46,
							67,
							142,
							74,
							111,
							74,
							79,
							93,
							78,
							88,
							82,
							83,
							67,
							27
						]
					},
					"words": {
						"starts": [
							105,
							166,
							248,
							250,
							275,
							294,
							316,
							354,
							390,
							422,
							488,
							515,
							530,
							580,
							619,
							621,
							730,
							733,
							795,
							797,
							802,
							823,
							886,
							920,
							973,
							1008,
							1020,
							1059,
							1261,
							1269,
							1329,
							1344,
							1378,
							1430,
							1448,
							1469,
							1487,
							1503,
							1547,
							1596,
							1697,
							1700,
							1730,
							1804,
							2146,
							2401,
							2428,
							2476,
							2494,
							2533,
							2577,
							2593,
							2617,
							2635,
							2658,
							2678,
							2702,
							2447,
							2764,
							2786,
							2812,
							2833,
							2854,
							2928,
							2945,
							2266,
							2356,
							2235,
							2244
						],
						"lengths": [
							60,
							79,
							0,
							23,
							16,
							19,
							35,
							33,
							24,
							64,
							24,
							11,
							47,
							36,
							0,
							104,
							1,
							57,
							0,
							2,
							18,
							60,
							30,
							33,
							31,
							4,
							38,
							197,
							5,
							57,
							12,
							30,
							48,
							16,
							19,
							16,
							14,
							42,
							47,
							34,
							1,
							27,
							71,
							329,
							12,
							20,
							6,
							6,
							17,
							12,
							9,
							6,
							12,
							11,
							8,
							6,
							10,
							17,
							10,
							14,
							9,
							9,
							10,
							11,
							11,
							10,
							9,
							7,
							3
						]
					}
				}
			},
			"minorChanges": {
				"source": {
					"chars": {
						"starts": [
							1290,
							1684,
							1882,
							2023,
							2165,
							2391,
							2623,
							2813,
							3647,
							4194,
							4397,
							4484,
							4833,
							5078,
							5101,
							5850,
							5882,
							6293,
							6326,
							6377,
							6500,
							6931,
							7181,
							7416,
							7796,
							7811,
							9722,
							10126,
							10226,
							10481,
							10879,
							10894,
							11196,
							12108,
							12628,
							13108,
							15325,
							15784,
							15987,
							18051,
							26736
						],
						"lengths": [
							12,
							15,
							15,
							13,
							11,
							12,
							14,
							26,
							16,
							20,
							9,
							17,
							14,
							13,
							14,
							22,
							11,
							21,
							14,
							10,
							15,
							11,
							17,
							143,
							12,
							17,
							10,
							14,
							13,
							24,
							12,
							14,
							18,
							20,
							15,
							10,
							159,
							8,
							7,
							5,
							8
						]
					},
					"words": {
						"starts": [
							191,
							239,
							264,
							282,
							303,
							340,
							375,
							401,
							529,
							601,
							627,
							640,
							689,
							727,
							729,
							835,
							838,
							897,
							899,
							903,
							923,
							985,
							1017,
							1052,
							1097,
							1098,
							1362,
							1421,
							1435,
							1467,
							1517,
							1518,
							1558,
							1689,
							1759,
							1832,
							2163,
							2220,
							2244,
							2514,
							3621
						],
						"lengths": [
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							12,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							15,
							0,
							0,
							0,
							0
						]
					}
				},
				"suspected": {
					"chars": {
						"starts": [
							2096,
							2141,
							2339,
							2477,
							2623,
							2854,
							3090,
							3285,
							3340,
							3818,
							4021,
							4107,
							4464,
							4713,
							4742,
							5490,
							5536,
							5946,
							5993,
							6041,
							6168,
							6604,
							6858,
							7101,
							7505,
							7527,
							9383,
							9793,
							9897,
							10158,
							10564,
							10585,
							10874,
							11745,
							12842,
							13331,
							15579,
							19025,
							19230,
							21417,
							16533
						],
						"lengths": [
							9,
							9,
							9,
							10,
							8,
							9,
							11,
							10,
							10,
							14,
							8,
							9,
							10,
							9,
							8,
							10,
							5,
							9,
							8,
							6,
							11,
							7,
							9,
							166,
							9,
							11,
							6,
							10,
							9,
							16,
							8,
							8,
							9,
							11,
							11,
							6,
							131,
							7,
							7,
							4,
							8
						]
					},
					"words": {
						"starts": [
							246,
							249,
							274,
							292,
							314,
							352,
							388,
							415,
							421,
							487,
							514,
							527,
							578,
							617,
							620,
							726,
							732,
							791,
							796,
							800,
							821,
							884,
							917,
							954,
							1005,
							1007,
							1267,
							1327,
							1342,
							1375,
							1427,
							1429,
							1468,
							1595,
							1728,
							1802,
							2134,
							2422,
							2435,
							2587,
							2243
						],
						"lengths": [
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							18,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							0,
							11,
							0,
							0,
							0,
							0
						]
					}
				}
			},
			"relatedMeaning": {
				"source": {
					"chars": {
						"starts": [
							320,
							11788,
							15897,
							15902,
							24350
						],
						"lengths": [
							8,
							7,
							4,
							6,
							9
						]
					},
					"words": {
						"starts": [
							47,
							1640,
							2235,
							2236,
							3320
						],
						"lengths": [
							0,
							0,
							0,
							0,
							1
						]
					}
				},
				"suspected": {
					"chars": {
						"starts": [
							1119,
							11419,
							19058,
							19078,
							18173
						],
						"lengths": [
							7,
							6,
							2,
							73,
							87
						]
					},
					"words": {
						"starts": [
							104,
							1546,
							2425,
							2427,
							2355
						],
						"lengths": [
							0,
							0,
							0,
							0,
							0
						]
					}
				}
			}
		}
	}
}